\documentclass{article}
\usepackage[utf8]{inputenc}

\title{Arie}
\author{luca }
\date{March 2019}

\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage[leqno]{amsmath}
\usepackage{scalefnt}
\usepackage{fancybox}
\usepackage{float}
%\usepackage{natbib}
\usepackage{theorem}
\usepackage{lscape}
\usepackage{hyperref}

\setcounter{MaxMatrixCols}{10}

\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}{Criterion}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}[theorem]{Proposition}
{\theorembodyfont{\upshape} 
\newtheorem{remark}{Remark}
}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\newenvironment{proof}[1][Proof]{\textbf{#1.} }{\ \rule{0.5em}{0.5em}}
\setlength{\evensidemargin}{1in} 
\setlength{\oddsidemargin}{1in} 
\setlength{\topmargin}{0.8in} 
\setlength{\voffset}{-0.85in} 
\setlength{\hoffset}{-0.9in} 
\setlength{\textwidth}{6.8in} 
\setlength{\textheight}{8.95in}   
\newtheorem{Assumption}{Assumption}
\newtheorem{Result}[theorem]{Result}
\renewcommand{\cite}{\citet}
\usepackage[backend=biber,sorting=nyt]{biblatex}
\addbibresource{ambiguity.bib} %Imports bibliography file
\begin{document}

\title{Identification of Incomplete Preferences}
\author{Arie Beresteanu\thanks{%
Department of Economics, University of Pittsburgh, arie@pitt.edu. } \and %
Luca Rigotti\thanks{%
Department of Economics, University of Pittsburgh, luca@pitt.edu.}}
\date{February, 2019\thanks{%
We thank Richard Van Weelden for pointers and encouragements. We thank
Miriam Blumenthal for excellent RA work.}}
\maketitle

\begin{abstract}
This paper brings together two strands of recent literature: the one focused
on the consequences of incomplete preferences for economic outcomes, and the
one focused on the econometric identification of economic models that have
non-unique predictions. This connection is very natural because incomplete
preferences models typically yield multiplicity of outcomes. In particular,
we introduce an environment in which one can test the commonly held
assumption that preferences satisfy the completeness axiom using data
generated by the choices of heterogeneous individuals. We use methods from
random set theory, and results from the literature on partial
identification, to illustrate the connection between data and the
distribution of utility values in the population.

\bigskip

\noindent \textbf{Keywords}: Ambiguity, Incomplete Preferences, Knightian
Uncertainty, Partial Identification, Random Sets.

\bigskip

\textbf{Incomplete. Do not Cite. Do not distribute}.
\end{abstract}

\thispagestyle{empty}

\setlength{\baselineskip}{.26in}\newpage

\setcounter{page}{1}

\section{Introduction}
\label{introduction}

This paper ...

\section{Random Decision Makers}
\label{randomDecisionMakers}

In this section we consider random decision makers with heterogeneous preferences. Let $\left(I,\mathcal{F},P \right)$ be a probability space. Every decision maker $i\in I$ faces a universal set of alternatives denoted by $\mathcal{A}$ which is finite and contains at least two alternatives.

Every decision maker $i\in I$ has an interval order over the set of choices $\mathcal{A}$. For each $a\in A$, decision maker $i$ has a utility interval $\left[ \text{\b{u}}\left( a,i\right) ,\bar{u}\left( a,i\right) \right] $. We can, therefore, treat \b{u} and $\bar{u}$ as two random functions defined on 
$\mathcal{A}$. \footnote{It is common to assume that the utilities \b{u} and $\bar{u}$ are continuously distributed and thus the probability of ties is zero.} For every $a\in \mathcal{A}$, $\Pr \left[ \text{\b{u}}(a)\leq \bar{u}\left( a\right) \right] =1$.

Let $y_{i}$ denote the observed choice made by $i$, such that $y_{i}\in \mathcal{A}$. We may also observe additional vectors of relevant covariates for individual $i$ which we denote by $x_{i}$ and $z_{i}$ depending on the context. We bundle all the observable variables into one vector $w_{i}=\left( y_{i},x_{i}.z_{i}\right) $.

We denote the joint distribution of the observable variables as $P\left(w\right)$. We are interested to learn about the distribution of $\left(\text{\b{u}}\left( a\right) ,\bar{u}\left( a\right) \right)$ using
observational data from $P\left( w\right) $. Let $\theta $ denote a certain parameter from the joint distribution of the vector of $\left( \text{\b{u}} \left( a\right) ,\bar{u}\left( a\right) \right)$. For example, $\theta =\Pr \left( \text{\b{u}}(a)\leq 0\right) $. Let $\Theta$ be the set of all feasible values that $\theta $ can take. $\Theta $ is called the parameter space. Let $P\left( w;\theta \right) $ denote the joint distribution of the observables induced by a parameter $\theta \in \Theta $. The following
definition describes all the possible identification scenarios.

\begin{definition}
Let $\Theta _{I}=\left\{ \theta \in \Theta :P\left( w\right) =P\left( w;\theta \right) \right\} $ be the identification set.\newline
(i) The model is \emph{correctly specified} if $\Theta _{I}\neq \emptyset ,$%
otherwise the model is \emph{misspecified}.\newline
(ii) The model is \emph{point identified} if $\Theta _{I}=\left\{ \theta
^{\ast }\right\} $. \newline
(iii) The model is \emph{partially identified} if $\Theta _{I}\subset \Theta 
$ yet $\Theta _{I}$ is not a singleton nor the whole set $\Theta $.\newline
(iv) The model is \emph{unidentified} if $\Theta _{I}=\Theta $.
\end{definition}

The goal of this paper is to characterize $\Theta _{I}$ under various assumptions on the behavioral model.

The assumption that $V_{ij}$ is single valued corresponds to the assumption
that preferences are complete and any pair of alternatives is comparable for
each decision maker. Instead, we lift the completeness assumption and assume
that $V_{ij}$ are potentially interval valued. The \emph{interval order}
axiomatized by \cite{Fishburn-1970book} that is introduced in Section \ref%
{introduction} is a notable example for interval valued utility.\footnote{%
A strict preference $\prec $ is an interval order if it is irreflexive (not $%
x\prec x$) and satisfies a weak form of transitivity ($x\prec y$ and $z\prec
w$ $\Rightarrow $ $x\prec w$ or $z\prec y$).} In this model, $V_{ij}=\left[
u_{i}\left( j\right) ,u_{i}\left( j\right) +\sigma \left( j\right) \right] $
and the function $u\left( \cdot \right) $ represents the lower bound of the
utility interval. If for two different alternatives, $j$ and $j^{\prime }$,
the corresponding utility intervals overlap, $j$ and $j^{\prime }$ are not
comparable. Fishburn calls $\sigma $ a \emph{vagueness} function since it
measures the imprecision in a preference order.

\section{The General Case}

Let $A$ be a finite set of alternatives that decision makers face. For every $i\in I$ and $a\in A$, let $U(a,i)=[V_{L}(a,i),V_{H}(a,i)]$ be the interval representing the vagueness that agent $i$ has about the quality of alternative $a$. When we refer to the the random utility interval we denote it as $U(a)=[V_{L}(a),V_{H}(a)]$. For two intervals $A=[a_{L},a_{H}]$ and $B=[b_{L},b_{H}]$ we say that $A>B$ iff $a_{L}>b_{H}$. For every $a,a^{\prime}\in A$ and $a\neq a^{\prime }$, agent $i$ prefers $a$ over $a^{\prime }$ if \ $U(a,i)>U(a^{\prime },i)$. Finally, for a subset $A\subset A$ let $%
A^{c}=A\backslash A$.

For $i\in I$ we denote by $A(i)$ the set of alternatives that are not
dominated. In other words, 
\begin{align*}
A_{i}& =\{a\in A:\nexists b\in A\ \text{such that\ }V_{L}(b,i)>V_{U}(a,i)\}
\\
& =\{a\in A:\underset{b\in \{a\}^{c}}{\max }V_{L}(b,i)<V_{U}(a,i)\}\text{.}
\end{align*}%
$A(i)$ is a random set representing the predictions of the model.

Let $y(i)$ be the choice made by decision maker $i$. Rationality implies
that $y(i)\in A(i)$. Therefore, the random variable $y$ is a selection from
the random set $A$. For any subset $K\subset A$, the choice probabilities $%
\Pr (y_{i}\in K)$ are identified from the data. Following Artstein's
inequalities, we can say that $y$ is a selection of $A$ if and only if for
all $K\subset A$ 
\begin{equation}
C_{A}(K)\leq \Pr (y\in K),  \label{containment_inequality}
\end{equation}%
or equivalently that 
\begin{equation}
\Pr (y\in K)\leq T_{A}(K).  \label{capacity_inequality}
\end{equation}%
For completeness we compute here both the containment and capacity
functionals. First, 
\begin{align*}
C_{A}(K)& =\Pr (A\subset K) \\
& =\Pr (A\cap K^{c}=\varnothing ) \\
& =\Pr [\underset{k\in K^{c}}{\max }V_{U}(k)<\underset{a\in A}{\max }%
V_{L}(a)]\text{.}
\end{align*}%
Similarly, 
\begin{align*}
T_{A}(K)& =\Pr (A\cap K=\varnothing ) \\
& =1-\Pr [\underset{k\in K}{\max }V_{U}(k)<\underset{a\in A}{\max }V_{L}(a)]%
\text{.}
\end{align*}%
The inequalities in either (\ref{containment_inequality}) or (\ref%
{capacity_inequality}) impose restrictions on the joint distribution of the
random variables $\{V_{L}(a),V_{U}(a)\}_{a\in A}$. Let $P$ be the set of
probability distributions over the set $\{V_{L}(a),V_{U}(a)\}_{a\in A}$ such
that $V_{U}(a)\geq V_{L}(a)$ for all $a\in A$. Given our knowledge of $\{\Pr
(y\in K)\}_{K\subset A}$, the identification region is defined as%
\begin{equation*}
P^{I}=\{P\in P:C_{A}(K)\leq \Pr (y\in K)\forall K\subset A\}\text{.}
\end{equation*}

\begin{claim}
$P^{I}$ is a strict subset of $P$ if $\exists a \in A$ such that $1 >\Pr (y
=a) >0$.
\end{claim}

\begin{proof}
There is $a^{ \prime } \neq a$ such that $\Pr (y =a^{ \prime }) >0$.
Therefore, $\Pr (V_{L} (a) >V_{U} (a^{ \prime })) <1$. This is a restriction
on the joint distribution of $\{V_{L} (a) ,V_{U} (a)\}_{a \in A}$ that is
not included in the definition of $P$. Therefore, $P^{I}$ is a strict subset
of $P$.
\end{proof}

We now want to demonstrate that the conditions in Artstein's Lemma essential
in the sense that using less restrictions yields a strictly larger set than
the identification region. Let 
\begin{equation*}
P^{1}=\{P\in P:C_{A}(\{a\})\leq \Pr (y=a)\forall a\in A\}
\end{equation*}%
be the set of joint distributions that satisfy Artstein's Lemma only for
subsets of $A$ of cardinality $1$.

\begin{claim}
If $\vert A\vert >2$, $P^{1} \subsetneqq P^{I}$.
\end{claim}

\begin{proof}
Since $\vert A\vert >2$, there are two alternatives $a ,a^{ \prime } \in A$
such that $a \neq a^{ \prime }$ and $\{a ,a^{ \prime }\} \neq A$. By
Artsteins Lemma $C_{A} (\{a\}) \leq \Pr (y =a)$, $C_{A} (a^{ \prime }) \leq
\Pr (y =a^{ \prime })$ and $C_{A} (\{a ,a^{ \prime }\}) \leq \Pr (y \in \{a
,a^{ \prime }\})$. The first two inequalities yield $C_{A} (\{a\}) +C_{A}
(\{a^{ \prime }\}) \leq \Pr (y =a) +\Pr (y =a^{ \prime }) =\Pr (y \in \{a
,a^{ \prime }\})$ where the last equality is implied by $a \neq a^{ \prime }$%
. This inequality is included in the definition of $P^{1}$. Since $C_{A}
(\{a\}) +C_{A} (\{a^{ \prime }\}) \leq C_{A} (\{a ,a^{ \prime }\})$, the
inequality $C_{A} (\{a ,a^{ \prime }\}) \leq \Pr (y \in \{a ,a^{ \prime }\})$
may impose an additional restriction on the distribution of $y$ and
therefore on the joint distribution of $\{V_{L} (a) ,V_{U} (a)\}_{a \in A}$.
\end{proof}

Question: Let $A =\{j ,k ,l\}$, $V_{L} (j) =V_{U} (j) =0$ and $(V_{L} (k)
,V_{L} (l)) \sim F ( \cdot , \cdot )$, $V_{U} (k) =V_{L} (k) +\sigma (k)$, $%
V_{U} (l) =V_{L} (l) +\sigma (l)$. Can we produce pictures that show there
must be ambiguity for some agents?

\begin{example}
Let $A=\{0,1\}$. Let $V_{L}(0)=V_{U}(0)=0$. Let $V_{L}(1)=\beta -\varepsilon 
$ where $\varepsilon \sim F_{\varepsilon }$ such that $F_{\varepsilon }$ is
known and $E[\varepsilon ]=0$. Let $V_{U}(1)=V_{L}(1)+\sigma $ where $\sigma
\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{+}$. Let $y\in A$ be the choice made under rationality. We observe $%
p_{0}=\Pr (y=0)$ and $p_{1}=\Pr (y=1)$. Let $H$ be the set of all pairs $%
(\beta ,\sigma )$ that are consistent with the observed $(p_{0},p_{1})$. 
\newline
\relax\textbf{Case 1} (no ambiguity): Assume $\sigma =0$. $p_{1}=\Pr
(y=1)=\Pr $ $(\beta -\varepsilon >0)=\Pr (\varepsilon <\beta
)=F_{\varepsilon }(\beta )$. Therefore, $\beta =F_{\varepsilon }^{-1}(p_{1})$%
. The identification set is a singleton 
\begin{equation*}
H=\{(F_{\varepsilon }^{-1}(p_{1}),0)\}\text{.}
\end{equation*}%
\newline
\relax\textbf{Case 2} (ambiguity): $\sigma \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{+}$. We know that $p_{1}\geq \Pr (V_{L}(1)>0)=\Pr (\beta -\varepsilon
>0)=\Pr (\varepsilon <\beta )$. We also know that $p_{0}\geq \Pr
(V_{U}(1)<0)=\Pr (\beta +\sigma -\varepsilon <0)=\Pr (\varepsilon >\beta
+\sigma )=1-F_{\varepsilon }(\beta +\sigma )$. These inequalities imply that 
$F_{\varepsilon }(\beta )\leq p_{1}\leq 1-F_{\varepsilon }(\beta +\sigma )$.
In other words, $\beta \leq F_{\varepsilon }^{-1}(p_{1})\leq \beta +\sigma $%
. The identification set is 
\begin{equation*}
H=\{(\beta ,\sigma )\in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{+}:\beta <F_{\varepsilon }^{-1}(p_{1})<\beta +\sigma \}\text{.}
\end{equation*}%
This identification region contains the point $(F_{\varepsilon
}^{-1}(p_{1}),0)$. \newline
\relax\textbf{Case 3} (instrumental variable): As in Case 2, $\sigma \in \mathbb{R}_{+}$ but now we observe a random variable $Z$ with support $Z$ such that $Z$ does not affect the valuation but it may affect the choice in case of incompleteness. In other words, $\beta $ is not a function of $Z$ and $\varepsilon$ is independent of $Z$. We observe $p_{0|z}=\Pr (y=0|Z=z)$ and $p_{1|z}=\Pr (y=1|Z=z)$ for all $z\in Z$. Following the same analysis as above we can conclude that $\beta \leq \underset{z\in Z}{\min } F_{\varepsilon }(p_{1|z})$ and $\underset{z\in Z}{\max }F_{\varepsilon}^{-1}(p_{1|z})\leq \beta +\sigma $. The identification set is

\begin{equation*}
H=\{((\beta ,\sigma )\in  \mathbb{R} \times \mathbb{R}_{+}:\beta \leq \underset{z\in Z}{\min }F_{\varepsilon }(p_{1|z}),\underset{%
z\in Z}{\max }F_{\varepsilon }^{-1}(p_{1|z})\leq \beta +\sigma )\}\text{.}
\end{equation*}%
We can immediately see that if $\underset{z\in Z}{\max }F_{\varepsilon
}^{-1}(p_{1|z})>\underset{z\in Z}{\min }F_{\varepsilon }(p_{1|z})$ we can
rule out all points for which $\sigma =0$. In other words, if for different
values of $Z$ there are different choice probabilities this can only be a
result of ambiguity. \newline
\relax
\end{example}

\begin{example}
Let $A=\{a_{0},a_{1},a_{2}\}$ be the alternatives set. Suppose we normalize $%
V_{L}(a_{0})=V_{U}(a_{0})=0$. This is not a trivial normalization but we
make this assumption for two reasons. First, we need a location and scale
normalizations. This can be achieved by fixing the utility of alternative $%
a_{0}$ to zero and by setting the error terms distribution to one that has a
fixed variance. Second, to have a tractable example, we want to reduce the
number of parameters to be evaluated. For the other alternatives in $A$ we
assume%
\begin{equation*}
V_{L}(a_{j})=\beta _{0}+\beta _{1}X_{j}-\varepsilon
_{j},V_{U}(a_{j})=V_{L}(a_{j})+\delta _{j}\text{,}
\end{equation*}%
where $j=1,2.$ The parameter to be evaluated is $\theta =\{\beta _{0},\beta
_{1},\delta _{1},\delta _{2}\}\in \mathbb{R}^{2}\times \mathbb{R}_{+}^{2}$. For simplicity we assumed that the intercept and slope in $V_{L}$
are the same for both alternatives $a_{1}$ and $a_{2}$. To make this example
tractable we assume that $\varepsilon _{1}$ and $\varepsilon _{2}$ are
independent of each other and independent of the covariate $X$. If we assume
that $(\varepsilon _{1},\varepsilon _{2})$ are jointly Normal with vector
mean $0$ and the identity variance-covariance matrix $I_{2\times 2}$, we
have a Probit model with quality ambiguity. A similar extension of the Logit
model can be made if we assume a T1EV distribution instead. Denote the
cumulative distribution of $\varepsilon _{j}$ as $\Phi $ for both $j=1,2$.
To simplify notation, we are omitting conditioning on $(X_{1},X_{2})$ in all
probabilities below. Similarly to the discussion above we can see that 
\begin{align*}
1-\Pr (V_{U}(a_{j})& \geq \underset{k\in \{j\}^{c}}{\max }V_{L}(a_{k})) \\
& \geq p_{j}=\Pr (y=j) \\
& \geq \Pr (V_{L}(a_{j})\geq \underset{k\in \{j\}^{c}}{\max }V_{U}(a_{k}))%
\text{.}
\end{align*}%
Applying our assumptions we get 
\begin{align*}
& \Phi (\beta _{0}+\beta _{1}X_{1}+\delta _{1})\cdot \Phi (\beta _{0}+\beta
_{1}X_{2}+\delta _{2}) \\
& \leq p_{0}\leq \\
& 1-[1-\Phi (\beta _{0}+\beta _{1}X_{1})]\cdot \lbrack \Phi (\beta
_{0}+\beta _{1}X_{2})]
\end{align*}%
and similarly we can find inequalities for the other probabilities.
\end{example}

\textbf{Numerical example}

Consider the following model. The alternatives set is $A=\left\{
a_{0},a_{1},a_{2}\right\} \text{.}$ We make the following normalizations.
For $i\in \left\{ 0,1,2\right\} \text{,}$ 
\begin{align}
V_{L}\left( i\right) & =\beta _{i}+\varepsilon _{i} \\
V_{U}\left( i\right) & =V_{L}\left( i\right) +\sigma +\eta _{i}
\end{align}%
We set $\beta _{0}=0$ and $\sigma =1$. Therefore, we have only two
parameters to identify: $\beta _{1}$ and $\beta _{2}$. We made the following
parameter choice,%
\begin{equation}
\mathbf{\beta }=\left( 0,0.094,-0,054\right)
\end{equation}%
We let $\varepsilon _{i}$ and $\eta _{i}$ be i.i.d U$\left[ -0.25,0.25\right]
$. A data of $7250$ observations simulated from the above model was
generated. In other words, for each of the simulated $7250$ individuals we
generated $3$ intervals represented their utility intervals for the $3$
alternatives. We then had to make an arbitrary choice how these decision
makers break ambiguity. There are of course many ways to do that. Our choice
was to compute the mid-point of the $3$ intervals and to pick the
alternative with the highest value. As a result the sample we generated
produced the following choice probabilities vector for the $3$ alternatives,%
\begin{equation}
p=\left( 0.181,0.766,0.053\right) .
\end{equation}%
This vector is then passed to the next stage where we identify which pairs
of To check whether a certain pair of parameters is in the identification
region we have to verify $6$ inequalities. To do that we calculate the
capacity functionals by simulation and compare them to the vector of choice
probabilities above. The following scatter plot was generated using a
differential evolution algorithm.


\section{Abstaining}

Until this point we assumed that agents have to make a choice from the set
of alternatives $\mathcal{A}$. The important part of this assumption is that
a utility is assigned to each of the elements in the set $\mathcal{A}$,
potentially an interval. It is possible that $\mathcal{A}$ contains a 'no
action' alternative (e.g. do not buy any car) but this alternative gives a
certain utility to the DM which is often normalized to zero. There are
situations where the DM can abstain from making any choice. The most
prominent example is voting. When a DM (voter) comes to the polling place
she can chose to abstain from voting on some or all of the races on the
ballot. The utility associated with this choice is undefined. Denote the
extended alternatives set as,%
\begin{equation*}
\mathcal{\bar{A}}=\mathcal{A}\cup \left\{ \emptyset \right\} .
\end{equation*}%
In the case of voting, by abstaining the DM delegates the decision to other
DMs.

\section{Binary Choice}

In this section we focus on the binary choice models. Let the alternatives
set be $\mathcal{A}=\left\{ 0,1\right\} $ for all $i$. Let $%
(u_{i}(0),u_{i}(1))$ be such that%
\begin{eqnarray*}
u_{i}\left( 0\right) &=&0 \\
u_{i}\left( 1\right) &=&V_{i}
\end{eqnarray*}%
where $V:I\rightarrow 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
$ is a random variable representing the utility that agent $i$ assigns to
alternative $1$. In other words, every (random) individual $i$ is facing a
binary choice with the above payoffs. This model assumes that $V_{i}$ is
known to the decision maker and thus she can maximize her utility.

Let $y_{i}=\mathbf{1}\left[ u_{i}(1)>0\right] $. We denote the choice
probability of alternative $1$ by $p_{1}=\Pr \left( y_{i}=1\right) $ and the
choice probability of $0$ by $p_{0}=\Pr \left( y_{i}=0\right) $. It is clear
that $p_{1}=\Pr \left( V>0\right) $ and $p_{0}=\Pr \left( V<0\right) $.%
\footnote{%
We assume that $V$ is a continuous variable and thus $\Pr \left( V=0\right)
=0$ and thus we can ignore this event or add it to any other event.}
Typically $y$ is observed while $V$ is known only to the agent but is
unobserved by us. \ Therefore, the DGP identifies $p_{0}$ and $p_{1}$ and
thus it identifies $\Pr \left( V<0\right) $ and $\Pr \left( V>0\right) $
respectively. In \ the literature on discrete choice it is common to specify
a distribution function for $V$ which is known up to a finite parameter $%
\theta $. In this case, $\theta $ can be consistently and efficiently
estimated by maximum likelihood.

Suppose now that $V=[V_{L},V_{U}]$ where $V_{L}$ and $V_{U}$ are two random
variables such that $\Pr \left( V_{L}\leq V_{U}\right) =1$. We fix $u\left(
0\right) $ to be a singleton. In practice the decision maker can face
vagueness with respect to the utility from choice $0$ as well. Since what
matters is the order of the utilities resulting from alternatives $0$ and $1$%
, we can think about $V$ as the Hukuhara difference (see \cite{Hukuhara1967}%
) between the random sets representing the utility from alternative $1$ and
alternative $0$.

Given this vagueness about the utility from alternative $1$, the decision
maker's choice set is%
\begin{equation*}
Y=\left\{ 
\begin{array}{c}
\{1\} \\ 
\{0,1\} \\ 
\{0\}%
\end{array}%
\ 
\begin{array}{c}
if\ V_{L}>0 \\ 
0\in \left[ V_{L},V_{U}\right] \\ 
V_{U}<0%
\end{array}%
\right. .
\end{equation*}%
When $0\in \left[ V_{L},V_{U}\right] $ the decision maker is unsure how to
rank the two options she faces. Figure \ref{choicerule} illustrates the
decision rule.



As above, we denote the agent's choice by $y$. Following Artstein inequality%
\footnote{%
See \cite{Molchanov2005} Theorem 2.20 and Theorem 2.1 in \cite{BMM2012}.} $%
y\in Sel\left( Y\right) $ if and only if $\Pr \left( y\in K\right) \geq
C_{Y}\left( K\right) $ for every closed set $K$ where $C_{Y}\left( K\right) $
is the containment functional defined as $C_{Y}\left( K\right) =\Pr \left(
Y\subset K\right) $. Since $C_{Y}\left( \{0\}\right) =\Pr \left(
V_{U}<0\right) $ and $C_{Y}\left( \left\{ 1\right\} \right) =\Pr \left(
V_{L}>0\right) $, for any $y\in Sel\left( Y\right) $, $\Pr (y=0)\geq \Pr
\left( V_{U}<0\right) $ and $\Pr \left( y=1\right) \geq \Pr \left(
V_{L}>0\right) $. Using the fact that $\Pr \left( y=0\right) =1-\Pr (y=1)$,
we can conclude that%
\begin{equation}
\Pr \left( V_{U}<0\right) \leq \Pr (y=0)\leq \Pr \left( V_{L}<0\right) .
\label{Artstein}
\end{equation}%
Without observing $y$\ the probability $\Pr \left( y=0\right) $ is
unidentified and inequality (\ref{Artstein}) implies only that $\Pr \left(
V_{U}<0\right) \leq \Pr \left( V_{L}<0\right) $. This is immediate from our
initial assumption that $\Pr \left( V_{L}\leq V_{U}\right) =1$. Suppose we
observe data on choices made by decision makers facing the type of
incompleteness described above. Since we can identify $p_{1}$ and $p_{0}$
from the data, inequality (\ref{Artstein}) becomes%
\begin{equation}
\Pr \left( V_{U}<0\right) \leq p_{0}\leq \Pr \left( V_{L}<0\right) .
\label{ineq1}
\end{equation}%
Without further assumptions this is the only information we can draw about
the joint distribution of $V_{L}$ and $V_{U}$. We cannot reject, for
example, the hypothesis that $V_{L}=V_{U}$, $P-a.s.$ and there is no
vagueness about choice $1$. \ Moreover, the above inequality bound the
marginal cumulative distributions of $V_{L}$ and $V_{U}$ at the point $0$
but does not provide information on their joint distribution or other
features of their marginal distributions. Another parameter of interest here
is the proportion of decision makers who have incomplete preferences. This
proportion is $\Pr \left( V_{L}<0\ \wedge V_{U}>0\right) =1-\Pr \left(
V_{L}>0\right) -\Pr \left( V_{U}<0\right) =\Pr \left( V_{L}<0\right) -\Pr
\left( V_{U}<0\right) $. Again, this quantity can be anywhere between zero
and one.


Figure \ref{impreciseutilityidentification} illustrates the information
contained in inequality (\ref{ineq1}). Before observing any data the only
information we have is that $V_{L}\leq V_{U}$ for every individual $i$.
Therefore, $\Pr \left( V_{L}<0\right) \geq \Pr \left( V_{U}<0\right) $. The
area under the $45{{}^\circ}$ line represents this information. After observing data we can identify the
frequency $p_{0}=\Pr \left( y=0\right) $. Inequality (\ref{ineq1}) then puts
restrictions on the values that the cumulative distributions of $V_{L}$ and $%
V_{U}$ can take at the point $0$. For example, say $p_{0}=0.37$. We can no
longer admit the case where $\Pr \left( V_{L}<0\right) =0.3$ and $\Pr \left(
V_{U}<0\right) =0.25$. Similarly we cannot admit the case where $\Pr \left(
V_{L}<0\right) =0.5$ and $\Pr \left( V_{U}<0\right) =0.4$. The two triangles
corresponding to these cases are eliminated from the identification region
after observing data. The remaining identification region is the rectangle
north-west of the point $\left( p_{0},p_{0}\right) $. Note that the case
where $\Pr (V_{L}<0)=\Pr \left( V_{U}<0\right) =0.37$ is included in the
identification region. The fact that these two probabilities are equal to
each other does not necessarily mean that there is no incompleteness and
that $V_{L}=V_{U}$ for all $i$. It is still possible that the quality of
choice $1$ is not known to the agent precisely but $\Pr \left(
0<V_{L}<V_{U}\right) =0.37$ and $\Pr \left( V_{L}<V_{U}<0\right) =0.63$. In
other words, there is incompleteness but it is choice irrelevant.

The point $\left( p_{0},p_{0}\right) $ in Figure \ref%
{impreciseutilityidentification} represents a situation where $\Pr \left(
V_{U}<0\right) =p_{0}=\Pr \left( V_{L}<0\right) $ and therefore no DM has
incomplete preferences. On the otherhand the point $\left( 1,0\right) $
represents a situation where $0=\Pr \left( V_{U}<0\right) <\Pr \left(
V_{L}<0\right) =1$ and all DMs cannot rank the two alternatives. It is
natural to ask what is the identification region if we know that at least a
proportion $\alpha \in \left( 0,1\right) $ of decision makers cannot rank
the alternatives. Using the same reasoning as above, we have $\alpha \leq
\Pr \left( V_{L}<0\ \wedge V_{U}>0\right) =1-\Pr \left( V_{L}>0\right) -\Pr
\left( V_{U}<0\right) =\Pr \left( V_{L}<0\right) -\Pr \left( V_{U}<0\right) $%
. Therefore, this information adds the restriction that 
\begin{equation}
\Pr \left( V_{U}<0\right) \leq \Pr \left( V_{L}<0\right) -\alpha .
\label{ineq2}
\end{equation}


Figure \ref{impreciseutilityidentification2} depicts the identification
region consistent with both inequalities (\ref{ineq1}) and (\ref{ineq2}).
The dark region in Figure \ref{impreciseutilityidentification2} includes all
the points which are consistent with the statement that at least an $\alpha $
proportion of the DMs cannot rank the two alternatives in addition to the
observation that $p_{0}$ portion of DMs eventually chose alternative $0$.

The theory we have presented so far makes few assumptions. Our results
illustrate that identification, albeit partial, is possible when preferences
are not complete. Next, we illustrate how further assumptions can lead to
even stronger conclusions in terms of identification. First, we briefly
discuss assumptions on the joint distribution of $\left( V_{L},V_{U}\right) $%
. Then, we show that the presence of particular instruments can lead to a
rejection of the hypothesis that all consumers' preferences are complete.
Finally, we discuss a possible way to break incompleteness using the idea of
regret.

\subsection{Assumptions on the joint distribution of $\left(
V_{L},V_{U}\right) $}

Suppose further that $\left( V_{L},V_{U}\right) \sim F\left( \cdot ,\cdot
;\theta \right) $ where $\theta \in \Theta $ a finite dimensional parameter
space. Under this assumption, the identification region is 
\begin{equation}
\Theta _{I}=\left\{ \theta \in \Theta :F_{L}\left( 0;\theta \right) \leq
p_{0}\leq F_{U}\left( 0;\theta \right) \right\}  \label{ID1}
\end{equation}%
where $F_{L}\left( t;\theta \right) =\int_{-\infty }^{\infty }\int_{-\infty
}^{t}F\left( u,v;\theta \right) dvdu$ is the marginal distribution of $V_{L}$
and similarly $F_{U}\left( t;\theta \right) =\int_{-\infty }^{\infty
}\int_{-\infty }^{t}F\left( u,v;\theta \right) dudv$ is the marginal
distribution of $V_{U}$. Note that parts of $\theta $ that do not appear in
either $F_{L}$ or $F_{U}$ cannot be identified at all.

Models of binary choice often make the assumption that $u_{1i}=V+\varepsilon 
$ where $V$ is the average utility of choice $1$ and $\varepsilon $ has a
parametric distribution $F_{\varepsilon }$ with mean zero and a known
constant variance. Two prominent choices for $F_{\varepsilon }$ are the
standard normal distribution leading to a Probit model and the logistic
distribution leading to the Logit model. In both these cases, there are no
unknown parameters in $F_{\varepsilon }$ and the only unknown parameter is $%
V $. Extending this model to accommodate incompleteness can be done in
several ways. Here we assume that the decision maker is unsure about the
average utility of choice $1$. Specifically we assume that $V_{L}=\bar{V}%
_{L}+\varepsilon $ and $V_{U}=\bar{V}_{U}+\varepsilon $. \ Under this model
the identification region for $\left( V_{L},V_{U}\right) $ is 
\begin{equation}
\Theta _{I}=\left\{ \left( \bar{V}_{L},\bar{V}_{U}\right) :\bar{V}_{L}\leq
F_{\varepsilon }^{-1}(p_{0})\leq \bar{V}_{U}\right\} .  \label{ID2}
\end{equation}%
Inequality (\ref{ID2}) imposes restrictions on the possible values of the
pair $\left( \bar{V}_{L},\bar{V}_{U}\right) $. Again, the weak inequalities
in (\ref{ID2}) imply that the hypothesis $\bar{V}_{L}=\bar{V}_{U}$ cannot be
rejected even in this simple model. Moreover, the difference $\bar{V}_{U}-%
\bar{V}_{L}$ is unbounded. Note, however, that inequality (\ref{ID2}) is
written in terms of the values $\left( \bar{V}_{L},\bar{V}_{U}\right) $ and
not in terms of their distribution functions as in inequality (\ref{ineq1}).
If $\varepsilon $ is symmetric around $0$, then if $p_{0}<\frac{1}{2}$, $%
\bar{V}_{L}<0$. If on the other hand $p_{0}>\frac{1}{2}$, $\bar{V}_{U}>0$.
In other words, this model allows us to sign one value of the pair $\left( 
\bar{V}_{L},\bar{V}_{U}\right) $. Furthermore, if we observe a vector of
covariates $X$ and say that $\left( \bar{V}_{L},\bar{V}_{U}\right) $ are
each a linear function of the covariates, we can create and interval Logit
or Probit. Further developing this model is part of our research agenda.

\subsection{Instrumental variables}

\subsubsection{Perfect Instruments}

In this section we show how one could use instrumental variables to further
refine the identification region established in the general case. In
particular, valid instruments have the characteristic of influencing choice
between incomparable alternatives while having no effect on preferences. One
example of these can be thought of as \textquotedblleft
frames\textquotedblright\ in the sense of behavioral economics. This is the
well documented phenomenon that sometimes presenting the same information in
differing fashion may lead to different choices. If these instruments exist,
they can be used to rule out the possibility that all decision makers have
complete preferences.

Suppose there is a variable $Z$ with a support $\mathcal{Z}$ such that $%
\left( V_{L},V_{U}\right) $ are independent of $Z$. The choice $y$, however,
may depend on the instrument. For every $z\in \mathcal{Z}$, let $p_{0|z}=\Pr
\left( y=0|Z=z\right) $. This means that when the decision maker cannot
compare the two alternatives, the choice between $0$ and $1$ may depend on $%
Z $.

\begin{theorem}
Suppose $\left( V_{L},V_{U}\right) $ is independent of $Z.$ Then,%
\begin{equation*}
\Pr \left( V_{U}<0\right) \leq \inf_{z\in \mathcal{Z}}p_{0|z}\ \wedge \
\sup_{z\in \mathcal{Z}}p_{0|z}\leq \Pr \left( V_{L}<0\right) .
\end{equation*}
\end{theorem}

If $Z$ affects the choice, then $\inf_{z\in \mathcal{Z}}p_{0|z}<\sup_{z\in 
\mathcal{Z}}p_{0|z}$. In this case we can reject the hypothesis that $%
V_{L}=V_{U}$ and confirm that some decision makers have incomplete
preferences. Figure \ref{IDinstrumental} shows that the identification
region for $\left( \Pr \left( V_{U}<0\right) ,\Pr \left( V_{L}<0\right)
\right) $ in the presence of an instrumental which is the dark shaded area
does not touch the $45^{o}$ line. Therefore, the amount of vagueness can be
measured by $\Pr \left( V_{L}<0\right) -\Pr \left( V_{U}\right) \geq
\sup_{z\in \mathcal{Z}}p_{0|z}-\inf_{z\in \mathcal{Z}}p_{0|z}$.


Moreover, if we assume that there is a vector of covariates $x\in \mathbb{R}^{k}$ such that $V_{L}=x^{\prime }\gamma _{L}+\varepsilon $ and $%
V_{U}=x^{\prime }\gamma _{U}+\varepsilon $. In this case the identification
region is%
\begin{equation*}
\Theta _{I}=\left\{ \left( \gamma _{L},\gamma _{U}\right) :x^{\prime }\gamma
_{U}\leq \inf_{z\in \mathcal{Z}}F_{\varepsilon }^{-1}(p_{0|z})\ \wedge \
\sup_{z\in \mathcal{Z}}F_{\varepsilon }^{-1}(p_{0|z})\leq x^{\prime }\gamma
_{L}\right\}
\end{equation*}

\subsubsection{Imperfect Instruments}

In this section we relax the strong assumption that $\left(
V_{L},V_{U}\right) $ is independent of $Z$. \ \cite{NevoRosen} introduced
the notion of imperfect instrumental variables in a linear regression model
with endogeneous regressors. An imperfect instrumental variable is a
situation where a variable $Z$ is correlated with the error term of the
regression but to a much lesser degree than its correlation with the
endogeneous regressor. \cite{NevoRosen} show that under some conditions this
situation lends itself to partial identification of the regression
parameters. We adjust this notion of imperfect instrumental variables to our
model of choice with vagueness. We define the following quantities.%
\begin{eqnarray*}
\delta _{L} &=&\sup_{z\in \mathcal{Z}}\left\vert \Pr \left(
V_{L}<0|Z=z\right) -\Pr \left( V_{L}<0\right) \right\vert \\
\delta _{U} &=&\sup_{z\in \mathcal{Z}}\left\vert \Pr \left(
V_{U}<0|Z=z\right) -\Pr \left( V_{U}<0\right) \right\vert
\end{eqnarray*}%
and%
\begin{equation*}
\Delta _{0}=\sup_{z\in \mathcal{Z}}p_{0|z}-\inf_{z\in \mathcal{Z}}p_{0|z}.
\end{equation*}

\begin{theorem}
Suppose $\Delta _{0}>\delta _{L}+\delta _{U}$, then $\Pr \left(
V_{U}<0\right) $ is bounded away from $\Pr \left( V_{L}<0\right) $ by a
strictly positive quantity.
\end{theorem}

\begin{proof}
For all $z\in Z$, 
\begin{equation*}
\Pr (V_{U}<0)-\delta _{U}\leq \Pr \left( V_{U}<0|Z=z\right) \leq p_{0|z}
\end{equation*}%
and thus,%
\begin{equation*}
\Pr (V_{U}<0)\leq p_{0|z}+\delta _{U}.
\end{equation*}%
As a result we can say that%
\begin{equation*}
\Pr \left( V_{U}<0\right) \leq \inf_{z\in \mathcal{Z}}p_{0|z}+\delta _{U}.
\end{equation*}%
Similarly, since 
\begin{equation*}
p_{0|z}\leq \Pr \left( V_{L}<0|Z=z\right) \leq \Pr (V_{L}<0)+\delta _{L}.
\end{equation*}%
Using the same steps as above we get that%
\begin{equation*}
\sup_{z\in \mathcal{Z}}p_{0|z}-\delta _{L}\leq \Pr \left( V_{L}<0\right) .
\end{equation*}%
It is now clear that 
\begin{equation*}
\Pr (V_{U}<0)-\Pr \left( V_{L}<0\right) >\Delta _{0}-\delta _{L}-\delta
_{U}>0.
\end{equation*}
\end{proof}

\subsection{Minmax regret}

The observed choice, $y$, is a selection from the random set $Y$. We could
establish only very general bounds on the distribution of $\left(
V_{L},V_{U}\right) $ because we made no assumptions on the selection $y$ in
case in which the consumer cannot compare alternatives. So far, we have been
silent about the way the decision maker makes her choice when $Y\left(
\omega \right) =\left\{ 0,1\right\} $. This approach resulted in partial
identification of the parameters of interest as described above. Next, we
focus on the idea of minimizing maximal regret as a way to break the
consumer's indecision.

Suppose that $\left( V_{L},V_{U}\right) \sim F$ for some joint distribution $%
F$ (it can be a parametric distribution as before). If $V_{U}<0$, the
decision maker chooses choice $0.$ Similarly if $V_{L}>0$, the decision
maker chooses choice $1$. The interesting case occur when $V_{L}<0<V_{U}$.
Both choices in this case may be rational. To break the tie the decision
maker can use the minimax regret rule. In other words, we assume that $y_{i}$
is such that $i$ minimizes the maximum regret she can have when the true
value of choice $1$ is realized. If $i$ chooses $1$, the maximal regret is $%
\left\vert V_{L}\right\vert $ and if $i$ chooses $0$, the maximal regret is $%
V_{U}$. Therefore, $i$ chooses $1$ if $V_{U}\geq \left\vert V_{L}\right\vert 
$ and chooses $0$ otherwise. This is summarized in the following equation.
For each $i$,%
\begin{equation}
y=\left\{ 
\begin{array}{c}
1 \\ 
0%
\end{array}%
\ 
\begin{array}{c}
if\ V_{L}>0\ or\ (V_{L}<0<V_{U}\ and\ V_{U}>|V_{L}|) \\ 
if\ V_{U}<0\ or\ (V_{L}<0<V_{U}\ and\ V_{U}>|V_{L}|)%
\end{array}%
\right. .  \label{minimaxrule}
\end{equation}%
In other words, the minimax regret rule picks one selection from the random
set $Y$. Therefore, $p_{0}=\Pr \left( V_{U}<0\ or\ (V_{L}<0<V_{U}\ and\
V_{U}>|V_{L}|)\right) $. Figure \ref{choiceruleregret} describes the choice
rule in (\ref{minimaxrule}). As one can see, the region where choice was
indeterminate, the ortant where $V_{U}$ is positive and $V_{L}$ is negative,
is now allocated to each alternative so that points above the 45 degree line
mean alternative $1$ is chosen and point below it mean alternative $0$ is
chosen. Adding a parametric assumption on the joint distribution of $\left(
V_{L},V_{U}\right) $ will allow us to point identify the finite parameter of
that distribution. Specifically if we assume that $V_{L}=\bar{V}%
_{L}+\varepsilon $ and $V_{U}=\bar{V}_{U}+\varepsilon $ and $\varepsilon
\sim F_{\varepsilon }$ for a known distribution $F_{\varepsilon }$, then we
can identify the pair $\left( \bar{V}_{L},\bar{V}_{U}\right) $.


\section{Discrete Choice With Knightian Uncertainty}

Next, we discuss how this framework can be extended to allow for ambiguity
and Knightian uncertainty as described in \cite{Bewley86}.\footnote{%
Bewley's original paper has been published recently as \cite{Bewley02}.}
That paper shows that a strict preference relation that is not necessarily
complete, but satisfies all other axioms of the standard Anscombe-Aumann
framework, can be represented by a family of expected utility functions
generated by a unique utility index and a set of probability distributions.%
\footnote{%
Incompleteness in decision making in a von-Neumann and Morgenstern
environment was first studied by \cite{Aumann62}, which obtains a
representation in which the probability is unique but there are multiple
utility functions.} Lack of completeness is thus reflected in multiplicity
of beliefs: the unique subjective probability distribution of the standard
expected utility framework is replaced by a set of probability
distributions, and when the preference relation is complete this set becomes
a singleton.

We let $S$ denote the state space and, with abuse of notation, also the
cardinality of that space. There are $J$ possible choices, and the utility
of each choice depends on the state that is realized. Therefore, for each
choice $j\in J$ we specify the utility that choice yields in each state.
Formally, the utility of an individual for choice $j$ in state $s$ is
denoted as $u\left( j,s\right) $. Let $\Delta (S)$ be the set of all
probability distributions over $S$. If $\pi \in \Delta (S)$, the expected
utility of individual $i$ according to that probability is given by 
\begin{equation*}
E_{\pi }\left[ u\left( j\right) \right] \equiv \sum_{s\in S}\pi \left(
s\right) u\left( j,s\right)
\end{equation*}%
Bewley's theory provides axioms on decision maker $i$'s preferences $\succ $%
; under these axioms there exists a closed and convex set $\Pi $ of
probability distributions on $S$ with the property that 
\begin{equation*}
j\succ k\qquad \text{if and only if}\qquad E_{\pi }\left[ u\left( j\right) %
\right] >E_{\pi }\left[ u\left( k\right) \right] \text{ for all }\pi \in \Pi
\end{equation*}%
If the inequality changes sign for different probability distributions the
two alternatives are not comparable. This is not a special case of the
interval order we studied in the previous section. Although all the possible
values of $E_{\pi }\left[ u_{i}\left( j\right) \right] $ describe an
interval as before, comparisons are made one probability distribution at the
time and not by looking at the extremes of that interval; two alternatives
could be ranked even if the corresponding intervals overlap. Despite this
difference, the results of the previous section can be applied here by
taking advantage of some simple algebra.

The expression above can be rewritten in terms of the expected value of the
utility difference between the two alternatives as:%
\begin{equation*}
j\succ k\qquad \text{if and only if}\qquad E_{\pi }\left[ u\left( j\right)
-u\left( k\right) \right] >0\text{ for all }\pi \in \Pi
\end{equation*}%
and therefore one obtains%
\begin{equation*}
j\succ k\qquad \text{if and only if}\qquad E_{\pi ^{min}}\left[ u\left(
j\right) -u\left( k\right) \right] >0
\end{equation*}%
and 
\begin{equation*}
k\succ j\qquad \text{if and only if}\qquad E_{\pi ^{max}}\left[ u\left(
j\right) -u\left( k\right) \right] <0,
\end{equation*}%
where we defined $\pi ^{min}\in \arg \min_{\pi \in \Pi }E_{\pi }\left[
u\left( j\right) -u\left( k\right) \right] $ and $\pi ^{max}\in \arg
\max_{\pi \in \Pi }E_{\pi }\left[ u\left( j\right) -u\left( k\right) \right] 
$. This last two inequalities can now be used

Suppose the choice set $\mathcal{C}$ contains only alternatives $j$ and $k$.
Then, the decision maker's choices can be described by the following set%
\begin{equation*}
Y=\left\{ 
\begin{array}{c}
\{j\} \\ 
\{j,k\} \\ 
\{k\}%
\end{array}%
\ 
\begin{array}{c}
if\ E_{\pi ^{min}}\left[ u\left( j\right) -u\left( k\right) \right] >0 \\ 
0\in \left[ E_{\pi ^{min}}\left[ u\left( j\right) -u\left( k\right) \right]
,E_{\pi ^{max}}\left[ u\left( j\right) -u\left( k\right) \right] \right] \\ 
if\ E_{\pi ^{max}}\left[ u\left( j\right) -u\left( k\right) \right] <0%
\end{array}%
\right. .
\end{equation*}%
At this point, the same logic of the previous set can be applied to try and
identify properties of the probability distribution of $E_{\pi ^{min}}\left[
u\left( j\right) -u\left( k\right) \right] $ and $E_{\pi ^{max}}\left[
u\left( j\right) -u\left( k\right) \right] $. Before illustrating this,
however, note that individuals' choices will not reveal details about the
distribution of $\Pi $ and $u\left( \cdot \right) $ (the preference
parameters) beyond what one may learn from the two extreme expectations.

From now on, think of $E_{\pi ^{min}}\left[ u\left( j\right) -u\left(
k\right) \right] $ and $E_{\pi ^{max}}\left[ u\left( j\right) -u\left(
k\right) \right] $ as two random variables which obviously satisfy $\Pr
\left( E_{\pi ^{min}}\left[ u\left( j\right) -u\left( k\right) \right] \leq
E_{\pi ^{max}}\left[ u\left( j\right) -u\left( k\right) \right] \right) =1$.
In other words, while consumers may differ in either their utility function
for each alternative or in the probability they assign to each state of the
world, the only heterogeneity data can be informative about is the one of
these extreme expected values. As we observe individuals' choice that follow
the rule illustrated by the set $Y$, we use these observations to learn
about some features of the distribution of these random variables. By
applying Artstein's inequality here, we observe the following. When $%
K=\left\{ j\right\} $, we have 
\begin{equation*}
C_{Y}\left( \{j\}\right) =\Pr \left( Y\subset \{j\}\right) =\Pr \left(
E_{\pi ^{min}}\left[ u\left( j\right) -u\left( k\right) \right] >0\right) ,
\end{equation*}%
while when $K=\left\{ k\right\} $ we obtain 
\begin{equation*}
C_{Y}\left( \left\{ k\right\} \right) =\Pr \left( Y\subset \{k\}\right) =\Pr
\left( E_{\pi ^{max}}\left[ u\left( j\right) -u\left( k\right) \right]
<0\right) .
\end{equation*}%
Therefore, from Artstein inequality we conclude that%
\begin{equation*}
\Pr (y=j)\geq \Pr \left( E_{\pi ^{min}}\left[ u\left( j\right) -u\left(
k\right) \right] >0\right)
\end{equation*}%
and 
\begin{equation*}
\Pr \left( y=k\right) \geq \Pr \left( E_{\pi ^{max}}\left[ u\left( j\right)
-u\left( k\right) \right] <0\right)
\end{equation*}%
Using the fact that $\Pr \left( y=j\right) =1-\Pr (y=k)$, we can conclude
that 
\begin{equation*}
\Pr \left( E_{\pi ^{min}}\left[ u\left( j\right) -u\left( k\right) \right]
>0\right) \leq \Pr (y=j)\leq \Pr \left( E_{\pi ^{max}}\left[ u\left(
j\right) -u\left( k\right) \right] >0\right) .
\end{equation*}

As before, if the data identifies the values of $p_{k}$ and $p_{j}$ as the
probability that a randomly chosen individual will choose $k$ and $j$
respectively, the inequalities above imply that 
\begin{equation*}
\Pr \left( E_{\pi ^{min}}\left[ u\left( j\right) -u\left( k\right) \right]
>0\right) \leq p_{j}\leq \Pr \left( E_{\pi ^{max}}\left[ u\left( j\right)
-u\left( k\right) \right] <0\right) .
\end{equation*}%
Thus, knowledge about the probability that a randomly chosen individual will
choose $j$ implies restrictions on the marginal distributions of $E_{\pi
^{min}}\left[ u\left( j\right) -u\left( k\right) \right] $ and $E_{\pi
^{max}}\left[ u\left( j\right) -u\left( k\right) \right] $. In particular,
the lowest expected utility difference between $j$ and $k$ cannot be smaller
that the probability of choosing $j$, and the largest expected utility
difference between $j$ and $k$ cannot be larger that the probability of
choosing $j$.\ So, the inequality above says that data can impose
restrictions on preference parameters even when the underlying preferences
are not complete.

\subsection{ \boldmath{$\epsilon$} -contamination model}

We now specialize the model of decision making under uncertainty so that we
can learn more details about preferences from the partially identified
region for the probability distribution of the highest and lowest
expectations. In particular, we assume that $S$ has only two elements
(denoted $H$ and $L$) and that $\Pi =\left\{ (1-\varepsilon )\hat{\pi}%
+\varepsilon \pi :\pi \in \Delta ^{2}\right\} $ where $\Delta ^{2}$ is the
two dimensional simplex and $\varepsilon $ is a random variable that takes
values in the interval $\left[ 0,1\right] $. This is known as the $%
\varepsilon $-contamination model as the set $\Pi $ is constructed by
\textquotedblleft mixing\textquotedblright\ a reference distribution with
arbitrary distributions in the simplex. One can think of it as building a
probabilistic neighborhood of size epsilon around the reference measure. The
size of $\varepsilon $ is then a measure of the amount of ambiguity.

Consumers face two choices $\left\{ j,k\right\} $, and for simplicity we
assume that $u\left( j\right) =0$ in all states of the world.\footnote{%
By setting the utility of one option constant, we collapse reduce the model
of this section to the one of the previous section, in that the upper and
lower bounds on the expected utility of the uncertain options determine
behavior.} For option $k$, however, we assume the utility of each consumer
can be either $u_{L}$ or $u_{H}$, with $u_{L}<0<u_{H}$, depending on the
state of the world. The reference probability distribution is $\hat{\pi}%
=\left( \hat{\pi}_{L},\hat{\pi}_{H}\right) $. By construction, the
probabilities assigned to state $L$ satisfy%
\begin{equation*}
\left( 1-\varepsilon \right) \hat{\pi}_{L}\leq \pi _{L}\leq \left(
1-\varepsilon \right) \hat{\pi}_{L}+\varepsilon
\end{equation*}%
The bounds on the probability assigned to state $L$ induce bounds on the
expected utility from choosing option $k$; in particular,%
\begin{eqnarray*}
E_{\hat{\pi}}\left[ u\left( k\right) \right] &=&\hat{\pi}_{L}u_{L}+\hat{\pi}%
_{H}u_{H}+\left( \pi _{L}-\hat{\pi}_{L}\right) \varepsilon u_{L}+\left( \pi
_{H}-\hat{\pi}_{H}\right) \varepsilon u_{H} \\
&=&\bar{U}+\varepsilon \left[ \left( \pi _{L}-\hat{\pi}_{L}\right)
u_{L}+\left( \pi _{H}-\hat{\pi}_{H}\right) u_{H}\right] \\
&=&\bar{U}+\varepsilon \left[ \pi _{L}u_{L}+\pi _{H}u_{H}-\bar{U}\right]
\end{eqnarray*}%
where we use $\bar{U}$ to denote the expected utility of alternative $k$
according to the reference measure ($\bar{U}=\hat{\pi}_{L}u_{L}+\hat{\pi}%
_{H}u_{H}$). Therefore, since $u_{L}<0<u_{H}$, the highest and lowest
expected utility are given by%
\begin{equation*}
\bar{U}+\varepsilon \left( u_{H}-\bar{U}\right) \quad \text{and}\quad \bar{U}%
+\varepsilon \left( u_{L}-\bar{U}\right)
\end{equation*}%
respectively.

We can now use the inequalities implied by Artstein's inequality (here we
use $\bar{U}-\varepsilon \left( \bar{U}-u_{L}\right) $ instead of $V_{L}$,
and $\bar{U}+\varepsilon \left( u_{H}-\bar{U}\right) $ instead of $V_{U}$).
to derive that 
\begin{equation*}
\Pr \left( \bar{U}-\varepsilon \left( \bar{U}-u_{L}\right) <0\right) \geq
p_{0}\geq \Pr \left( \bar{U}+\varepsilon \left( u_{H}-\bar{U}\right)
<0\right) .
\end{equation*}%
These inequalities imply inequalities on the CDF\ of $\varepsilon $. With
some algebra we can show that

\begin{equation}
\Pr \left( \bar{U}-\varepsilon \left( \bar{U}-u_{L}\right) <0\right) =\Pr
\left( \varepsilon >\frac{\bar{U}}{\left( \bar{U}-u_{L}\right) }\right)
\label{Lconstraint}
\end{equation}%
and 
\begin{equation}
\Pr \left( \bar{U}+\varepsilon \left( u_{H}-\bar{U}\right) <0\right) =\Pr
\left( \varepsilon <-\frac{\bar{U}}{\left( u_{H}-\bar{U}\right) }\right) .
\label{Uconstraint}
\end{equation}%
By definition, we have that $u_{L}\leq \bar{U}\leq u_{H}$. If $\bar{U}>0$,
then the constraint (\ref{Uconstraint}) is non binding since $\Pr \left( 
\bar{U}+\varepsilon \left( u_{H}-\bar{U}\right) <0\right) $ is trivially
zero. On the other hand if $\bar{U}<0$, then the constraint in (\ref%
{Lconstraint}) is non binding since $\Pr \left( \bar{U}-\varepsilon \left( 
\bar{U}-u_{L}\right) <0\right) $ is trivially zero.

Let $\theta =\left( \hat{\pi},u_{L},u_{H},F_{\varepsilon }\right) \in \Theta
=\Delta ^{2}\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{-}\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{+}\times \Gamma $ be the parameter space where $\Gamma $ is the set of all
random variables on $\left[ 0,1\right] $. Using the definition of the
identification region in (\ref{ID1}) we can write the identification region
of the parameter $\theta $. It is easy to see that $\Theta $ is too high
dimensional and the identification region $\Theta _{I}$ in (\ref{ID1}) is
hard to characterize. At this point it is useful to fix some of the
dimensions and see what information can be drawn on the remaining
dimensions. We explore some of these options below by assuming that the
utility of option $k$ in each state as well as the probability distribution $%
\hat{\pi}$ are the same for all consumer. In this case, the only source of
heterogeneity is given by differences in the perception of ambiguity.

\textbf{Example}. Suppose $\hat{\pi},u_{L}$ and $u_{H}$ are fixed and $%
\varepsilon $ is distributed $B\left( \alpha ,\beta \right) $ for unknown $%
\alpha $ and $\beta $. The identification region is all the pairs of $\alpha 
$ and $\beta $ such that (\ref{Lconstraint}) and (\ref{Uconstraint}) are
satisfied. Figure (\ref{BetaID}) shows the possible pairs of $(\alpha ,\beta
)$ for $\hat{\pi}=\left( 0.6,0.4\right) $, $u_{L}=-2,$ $u_{H}=1$ and $%
p_{0}=0.37$.

Moreover, we can compute the identification rage for the average and
variance\ of $\varepsilon $. In the example above, the Beta distributions
admitted into the identification region have an expectation ranging from $%
0.55$ to $1$ and a variance of at most $0.22$. These numbers tell us about
the degree of ambiguity faced by the agents as suggested by the data.
Intuitively, the degree of ambiguity is high enough to offset the negative
expected value of alternative $k$.

\subsection{Voting in Ohio}

We apply the theory described above to voting in Ohio. The voting in Ohio
presents a neat IV example. It is known that the order of the candidates on
the ballot affects the chances of candidates to be elected. [ADD\ CITATIONS\
HERE] As a result ordering the candidates in alphabetical order may bias the
results in favor of candidates with certain family names.


\newpage \appendix

\section{Appendix A}

\section{Incomplete Probit Example}

Consider the following binary choice model. Let $\mathcal{A}=\left\{
0,1\right\} $ be the alternatives set. Normalize the utility from choice $%
u_{i}\left( 0\right) =0$ for all $i$. The utility from choice $1$ is vague.
we assume that $u_{i}\left( 1\right) \in \left[ \beta _{i},\beta _{i}+\delta
_{i}\right] $ where $\delta _{i}>0$ and the joint distribution of $\left(
\beta ,\delta \right) $ is unknown. From Artstein's inequalities we know that%
\begin{equation*}
\Pr \left( \beta +\delta <0\right) \leq p_{0}\leq \Pr \left( \beta <0\right)
.
\end{equation*}%
These two inequalities impose a certain restrictions on the joint
distribution of $\left( \beta ,\delta \right) $ but these restrictions are
limited.

\subsection{One dimensional heterogeneity}

Suppose now that $\beta _{i}=\beta -\varepsilon _{i}$ where $\varepsilon
_{i}\sim F_{\varepsilon }$ for a known distribution $F_{\varepsilon }$ (e.g.
a logistic or standard normal distribution). $\delta $ is assumed to be
constant across all decision maker. In other words, there is only one source
of heterogeneity. This implies that the following is an equivalent model.
Set $u_{i}\left( 0\right) =\varepsilon _{i}$ with $\varepsilon _{i}\sim
F_{\varepsilon }$ and $u_{i}\left( 1\right) =\beta +\delta $ constant for
all $i$.

Under these assumptions, $\Pr \left( \beta <0\right) =1-F_{\varepsilon
}\left( \beta \right) $ and $\Pr \left( \beta +\delta <0\right)
=1-F_{\varepsilon }\left( \beta +\delta \right) $. Since $p_{0}=1-p_{1}$, we
can write 
\begin{equation*}
F_{\varepsilon }\left( \beta +\delta \right) \leq p_{1}\leq F_{\varepsilon
}\left( \beta \right) ,
\end{equation*}%
or%
\begin{equation*}
\beta \leq F_{\varepsilon }^{-1}\left( p_{1}\right) \leq \beta +\delta .
\end{equation*}%
The identification region is, therefore, 
\begin{equation*}
\Theta ^{I}=\left\{ \left( \beta ,\delta \right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{+}:\beta \leq F_{\varepsilon }^{-1}\left( p_{1}\right) \leq \beta +\delta
\right\} .
\end{equation*}%
As before, suppose there is an additional variable $z$ independent of $%
\left( \beta ,\delta \right) $ with support $\mathcal{Z}$. In that case,%
\begin{equation*}
\Theta ^{I}=\left\{ \left( \beta ,\delta \right) \in 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
\times 
%TCIMACRO{\U{211d} }%
%BeginExpansion
\mathbb{R}
%EndExpansion
_{+}:\beta \leq \inf_{z\in \mathcal{Z}}F_{\varepsilon }^{-1}\left(
p_{0}|z\right) \ and\ \sup_{z\in \mathcal{Z}}F_{\varepsilon }^{-1}\left(
p_{0}|z\right) \leq \beta +\delta \right\} .
\end{equation*}





\newpage

\setcounter{page}{1} 
\printbibliography
\end{document}
